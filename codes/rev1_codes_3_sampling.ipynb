{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "significant-carry",
   "metadata": {
    "id": "suspected-immunology"
   },
   "source": [
    "# **핵심만 요약한 통계와 머신러닝 파이썬 코드북 개정1판**\n",
    "- ⓒ2023 AlgoBoni all rights reserved.\n",
    "- 본 컨텐츠의 저작권은 알고보니에 있습니다. 저작권법에 의해 보호를 받는 저작물이므로 무단 전재와 무단 복제를 금합니다.\n",
    "- 본 컨텐츠의 종이책은 [교보문고](https://product.kyobobook.co.kr/detail/S000209591909), [예스24](https://www.yes24.com/Product/Goods/122661688), [알라딘](https://www.aladin.co.kr/shop/wproduct.aspx?ISBN=K262935029&start=pnaver_02)에서 구매할 수 있습니다. 종이책에서는 아래 개념 및 코드에 대한 설명과 연습문제를 제공합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "american-unemployment",
   "metadata": {
    "id": "unique-kitchen"
   },
   "source": [
    "# 3. 표본추출, 데이터 분할, 교차검증\n",
    "## 3-1. 표본추출\n",
    "### - 단순랜덤추출법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "careful-acrylic",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "electrical-going",
    "outputId": "4290f40a-69ac-4ee9-c17d-0ccaffa100d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length  sepal width  petal length  petal width  target\n",
      "0           5.1          3.5           1.4          0.2     0.0\n",
      "1           4.9          3.0           1.4          0.2     0.0\n",
      "2           4.7          3.2           1.3          0.2     0.0\n",
      "3           4.6          3.1           1.5          0.2     0.0\n",
      "4           5.0          3.6           1.4          0.2     0.0\n"
     ]
    }
   ],
   "source": [
    "# Scikit learn의 내장 데이터 iris 불러오기\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "\n",
    "data = load_iris()\n",
    "iris_cols = list(data['feature_names']) + ['target']\n",
    "iris = DataFrame(np.c_[data['data'], data['target']], columns = [col.replace(\" (cm)\", \"\") for col in iris_cols])\n",
    "print(iris.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "ethical-priority",
   "metadata": {
    "id": "leading-immigration",
    "outputId": "3044c3c2-18a9-4d35-eea2-05ff3755ae61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sepal length  sepal width  petal length  petal width  target\n",
      "22           4.6          3.6           1.0          0.2     0.0\n",
      "39           5.1          3.4           1.5          0.2     0.0\n",
      "47           4.6          3.2           1.4          0.2     0.0\n"
     ]
    }
   ],
   "source": [
    "# 복원하지 않고 3개를 랜덤추출\n",
    "print(iris.sample(n=3, replace = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "designed-feeding",
   "metadata": {
    "id": "rubber-battery",
    "outputId": "2ac23846-cb78-4303-9d88-1dc813ef19fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sepal length  sepal width  petal length  petal width  target\n",
      "88           5.6          3.0           4.1          1.3     1.0\n",
      "67           5.8          2.7           4.1          1.0     1.0\n",
      "2            4.7          3.2           1.3          0.2     0.0\n",
      "91           6.1          3.0           4.6          1.4     1.0\n"
     ]
    }
   ],
   "source": [
    "# frac 파라미터로 전체 데이터의 3%를 랜덤추출\n",
    "print(iris.sample(frac=0.03))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "complex-denmark",
   "metadata": {
    "id": "ultimate-eating",
    "outputId": "0974461f-5911-4b9a-c3ca-dbab811ec293"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   petal length  sepal length  sepal width\n",
      "0           1.4           5.1          3.5\n",
      "1           1.4           4.9          3.0\n",
      "2           1.3           4.7          3.2\n"
     ]
    }
   ],
   "source": [
    "# 3개의 열(axis=1)을 랜덤 추출\n",
    "print(iris.sample(3, axis=1).head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "flexible-terror",
   "metadata": {
    "id": "convinced-browse",
    "outputId": "848f0acf-a2d9-4d84-ca78-f38ee5cfb5fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random.sample:  ['c', 'a', 'b', 3]\n",
      "np.random.choice ['a' '5' '2' '3']\n"
     ]
    }
   ],
   "source": [
    "# 리스트에서 단순랜덤추출하기\n",
    "import random\n",
    "import numpy as np\n",
    "data_list = [1,2,3,4,5,'a', 'b', 'c']\n",
    "print(\"random.sample: \", random.sample(data_list, 4))\n",
    "print(\"np.random.choice\", np.random.choice(data_list, 4, replace = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "determined-filename",
   "metadata": {
    "id": "numerical-court",
    "outputId": "04c6d40d-dba4-42e3-c704-61fd8b79d28d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0~10 사이의 정수 중 3개의 난수 생성:  [5 6 3]\n",
      "0~1 사이의 실수를 2*2 배열로 생성:\n",
      " [[0.25363176 0.9198194 ]\n",
      " [0.34766351 0.73365704]]\n"
     ]
    }
   ],
   "source": [
    "# [참고] 난수 생성하기\n",
    "print(\"0~10 사이의 정수 중 3개의 난수 생성: \", np.random.randint(0, 10, 3))\n",
    "print(\"0~1 사이의 실수를 2*2 배열로 생성:\\n\", np.random.rand(2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooperative-transformation",
   "metadata": {
    "id": "mathematical-bonus"
   },
   "source": [
    "### - 계통추출법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "friendly-statistics",
   "metadata": {
    "id": "adopted-pierre",
    "outputId": "11267b56-4f34-4cdf-e8d4-c5839ac3b953"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 150\n",
      "n: 8\n",
      "K: 18\n",
      "     sepal length  sepal width  petal length  petal width  target\n",
      "12            4.8          3.0           1.4          0.1     0.0\n",
      "30            4.8          3.1           1.6          0.2     0.0\n",
      "48            5.3          3.7           1.5          0.2     0.0\n",
      "66            5.6          3.0           4.5          1.5     1.0\n",
      "84            5.4          3.0           4.5          1.5     1.0\n",
      "102           7.1          3.0           5.9          2.1     2.0\n",
      "120           6.9          3.2           5.7          2.3     2.0\n",
      "138           6.0          3.0           4.8          1.8     2.0\n"
     ]
    }
   ],
   "source": [
    "# 계통추출법으로 표본 추출\n",
    "data, n = iris, 8 #모집단 데이터프레임, 추출할 샘플 수\n",
    "N = len(data) #모집단 데이터 크기\n",
    "K = N//n #구간 내 샘플 수\n",
    "index = data[:K].sample(1).index #첫 구간에서 임의로 선택한 샘플 인덱스\n",
    "#첫 샘플로부터 K개씩 띄어서 각 구간에서 하나씩 샘플을 추출\n",
    "sys_df = DataFrame()\n",
    "while len(sys_df) < n:\n",
    "    sys_df = sys_df.append(data.loc[index, :])\n",
    "    index += K\n",
    "\n",
    "print(f\"N: {N}\")\n",
    "print(f\"n: {n}\")\n",
    "print(f\"K: {K}\")\n",
    "print(sys_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indonesian-abraham",
   "metadata": {
    "id": "young-potential"
   },
   "source": [
    "### - 집락추출법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accredited-breeding",
   "metadata": {
    "id": "departmental-medicaid"
   },
   "source": [
    "### - 층화추출법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "sacred-outside",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    50\n",
      "2.0    50\n",
      "1.0    50\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# target을 층 혹은 집락이라고 가정!\n",
    "# 원본 데이터의 분포 확인\n",
    "from pandas import DataFrame, concat\n",
    "print(iris['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "informative-cyprus",
   "metadata": {
    "id": "empirical-victor"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal length  sepal width  petal length  petal width  target\n",
      "17            5.1          3.5           1.4          0.3     0.0\n",
      "43            5.0          3.5           1.6          0.6     0.0\n",
      "7             5.0          3.4           1.5          0.2     0.0\n",
      "82            5.8          2.7           3.9          1.2     1.0\n",
      "88            5.6          3.0           4.1          1.3     1.0\n",
      "66            5.6          3.0           4.5          1.5     1.0\n",
      "101           5.8          2.7           5.1          1.9     2.0\n",
      "140           6.7          3.1           5.6          2.4     2.0\n",
      "137           6.4          3.1           5.5          1.8     2.0\n"
     ]
    }
   ],
   "source": [
    "# 데이터, 층/집락 정보를 가진 컬럼명, 추출표본 개수\n",
    "data, stratum, sampling_no = iris, 'target', 9\n",
    "\n",
    "# 비례층화추출법: 원본 데이터의 비율대로 추출\n",
    "levels = data[stratum].unique()\n",
    "total = data[stratum].value_counts().sum()\n",
    "prop_val = data[stratum].value_counts()/total\n",
    "no = prop_val * sampling_no\n",
    "result = DataFrame()\n",
    "for level in levels:\n",
    "    temp_df = data[data[stratum]==level].sample(int(no[level]))\n",
    "    result = concat([result, temp_df])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "crucial-proposition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal length  sepal width  petal length  petal width  target\n",
      "31            5.4          3.4           1.5          0.4     0.0\n",
      "21            5.1          3.7           1.5          0.4     0.0\n",
      "82            5.8          2.7           3.9          1.2     1.0\n",
      "83            6.0          2.7           5.1          1.6     1.0\n",
      "64            5.6          2.9           3.6          1.3     1.0\n",
      "68            6.2          2.2           4.5          1.5     1.0\n",
      "69            5.6          2.5           3.9          1.1     1.0\n",
      "111           6.4          2.7           5.3          1.9     2.0\n",
      "127           6.1          3.0           4.9          1.8     2.0\n",
      "135           7.7          3.0           6.1          2.3     2.0\n"
     ]
    }
   ],
   "source": [
    "# 불비례층화추출법: 임의로 정한 특정 비율대로 샘플링\n",
    "# 데이터, 층/집락 정보를 가진 컬럼명, 추출표본 개수, 각 층/집락의 비율\n",
    "data, stratum, sampling_no, proportion = iris, 'target', 10, {0:0.2, 1:0.5, 2:0.3}\n",
    "\n",
    "levels = list(proportion.keys())\n",
    "prop_val = np.array(list(proportion.values()))\n",
    "total = sum(prop_val)\n",
    "no = prop_val * sampling_no\n",
    "result = DataFrame()\n",
    "for level in levels:\n",
    "    temp_df = data[data[stratum]==level].sample(int(no[level]))\n",
    "    result = concat([result, temp_df])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-quantum",
   "metadata": {
    "id": "numerical-hampshire"
   },
   "source": [
    "## 3-2. 데이터 분할\n",
    "### - 일반적 데이터 분할 및 홀드아웃 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automated-reynolds",
   "metadata": {
    "id": "thirty-enzyme",
    "outputId": "2fc0f3d0-34e9-4f9b-8281-5512bbe11e58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train(y_train): 105(105), X_test(y_test): 45(45)\n",
      "X_train의 비율: 0.70, X_test의 비율: 0.30 \n",
      "\n",
      "X_train(y_train): 75(75), X_test(y_test): 75(75)\n",
      "X_train의 비율: 0.50, X_test의 비율: 0.50\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = iris.drop('target', axis=1)\n",
    "y = iris.filter(['target'])\n",
    "\n",
    "# 일반적 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "print(\"X_train(y_train): %d(%d), X_test(y_test): %d(%d)\"%(len(X_train), len(y_train), len(X_test), len(y_test)))\n",
    "print(\"X_train의 비율: %0.2f, X_test의 비율: %0.2f\" %(len(X_train)/len(X), len(X_test)/len(X)), \"\\n\")\n",
    "\n",
    "# 홀드아웃방법\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
    "print(\"X_train(y_train): %d(%d), X_test(y_test): %d(%d)\"%(len(X_train), len(y_train), len(X_test), len(y_test)))\n",
    "print(\"X_train의 비율: %0.2f, X_test의 비율: %0.2f\" %(len(X_train)/len(X), len(X_test)/len(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italian-program",
   "metadata": {
    "id": "daily-frame"
   },
   "source": [
    "### - Shuffle Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "about-prairie",
   "metadata": {
    "id": "editorial-inquiry",
    "outputId": "93e42fc6-d488-4444-b2d0-a3c3c2f5c744"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0 ==> train_index: [ 91 107  42], test_index: [103 109  98]\n",
      "\tX_train의 비율: 0.50, X_test의 비율: 0.50\n",
      "\ty_train의 타겟 구성: Counter({0.0: 28, 1.0: 27, 2.0: 20})\n",
      "\ty_test의 타겟 구성: Counter({2.0: 30, 1.0: 23, 0.0: 22}) \n",
      "\n",
      "Sample 1 ==> train_index: [130 111 115], test_index: [109   4  43]\n",
      "\tX_train의 비율: 0.50, X_test의 비율: 0.50\n",
      "\ty_train의 타겟 구성: Counter({2.0: 29, 1.0: 27, 0.0: 19})\n",
      "\ty_test의 타겟 구성: Counter({0.0: 31, 1.0: 23, 2.0: 21}) \n",
      "\n",
      "Sample 2 ==> train_index: [44 53 69], test_index: [ 40  45 134]\n",
      "\tX_train의 비율: 0.50, X_test의 비율: 0.50\n",
      "\ty_train의 타겟 구성: Counter({0.0: 28, 1.0: 26, 2.0: 21})\n",
      "\ty_test의 타겟 구성: Counter({2.0: 29, 1.0: 24, 0.0: 22}) \n",
      "\n",
      "Sample 3 ==> train_index: [  9 137  54], test_index: [140 130  84]\n",
      "\tX_train의 비율: 0.50, X_test의 비율: 0.50\n",
      "\ty_train의 타겟 구성: Counter({2.0: 27, 0.0: 24, 1.0: 24})\n",
      "\ty_test의 타겟 구성: Counter({1.0: 26, 0.0: 26, 2.0: 23}) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "ss = ShuffleSplit(test_size=0.5, train_size=0.5, n_splits=4)\n",
    "for i, (train_index, test_index) in enumerate(ss.split(X)):\n",
    "    print(f\"Sample {i} ==> train_index: {train_index[:3]}, test_index: {test_index[:3]}\")\n",
    "    X_train, X_test, y_train, y_test = X.iloc[train_index, :], X.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n",
    "    print(\"\\tX_train의 비율: %0.2f, X_test의 비율: %0.2f\" %(len(X_train)/len(X), len(X_test)/len(X)))\n",
    "    print(\"\\ty_train의 타겟 구성:\", Counter(y_train['target']))\n",
    "    print(\"\\ty_test의 타겟 구성:\", Counter(y_test['target']), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-major",
   "metadata": {
    "id": "above-bulletin"
   },
   "source": [
    "### - K-fold 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bizarre-purple",
   "metadata": {
    "id": "eastern-peninsula",
    "outputId": "32a6704d-9f41-475c-c3ad-83565c24a4ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0 ==> train_index: [38 39 40], test_index: [0 1 2]\n",
      "\tX_train의 비율: 0.75, X_test의 비율: 0.25\n",
      "\ty_train의 타겟 구성: Counter({1.0: 50, 2.0: 50, 0.0: 12})\n",
      "\ty_test의 타겟 구성: Counter({0.0: 38}) \n",
      "\n",
      "Sample 1 ==> train_index: [0 1 2], test_index: [38 39 40]\n",
      "\tX_train의 비율: 0.75, X_test의 비율: 0.25\n",
      "\ty_train의 타겟 구성: Counter({2.0: 50, 0.0: 38, 1.0: 24})\n",
      "\ty_test의 타겟 구성: Counter({1.0: 26, 0.0: 12}) \n",
      "\n",
      "Sample 2 ==> train_index: [0 1 2], test_index: [76 77 78]\n",
      "\tX_train의 비율: 0.75, X_test의 비율: 0.25\n",
      "\ty_train의 타겟 구성: Counter({0.0: 50, 2.0: 37, 1.0: 26})\n",
      "\ty_test의 타겟 구성: Counter({1.0: 24, 2.0: 13}) \n",
      "\n",
      "Sample 3 ==> train_index: [0 1 2], test_index: [113 114 115]\n",
      "\tX_train의 비율: 0.75, X_test의 비율: 0.25\n",
      "\ty_train의 타겟 구성: Counter({0.0: 50, 1.0: 50, 2.0: 13})\n",
      "\ty_test의 타겟 구성: Counter({2.0: 37}) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from collections import Counter\n",
    "#n_splits=fold 개수, shuffle=데이터 분할 전 shuffle 여부\n",
    "kf = KFold(n_splits=4, shuffle=False) \n",
    "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    print(f\"Sample {i} ==> train_index: {train_index[:3]}, test_index: {test_index[:3]}\")\n",
    "    X_train, X_test, y_train, y_test = X.iloc[train_index, :], X.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n",
    "    print(\"\\tX_train의 비율: %0.2f, X_test의 비율: %0.2f\" %(len(X_train)/len(X), len(X_test)/len(X)))\n",
    "    print(\"\\ty_train의 타겟 구성:\", Counter(y_train['target']))\n",
    "    print(\"\\ty_test의 타겟 구성:\", Counter(y_test['target']), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extreme-kitchen",
   "metadata": {
    "id": "combined-remove"
   },
   "source": [
    "### - Stratified K-fold 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "whole-isolation",
   "metadata": {
    "id": "incorporated-blanket",
    "outputId": "d0c619e2-d031-4b21-9ed7-044796fa1db7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0 ==> train_index: [13 14 15], test_index: [0 1 2]\n",
      "\tX_train의 비율: 0.75, X_test의 비율: 0.25\n",
      "\ty_train의 타겟 구성: Counter({1.0: 38, 0.0: 37, 2.0: 37})\n",
      "\ty_test의 타겟 구성: Counter({0.0: 13, 2.0: 13, 1.0: 12}) \n",
      "\n",
      "Sample 1 ==> train_index: [0 1 2], test_index: [13 14 15]\n",
      "\tX_train의 비율: 0.75, X_test의 비율: 0.25\n",
      "\ty_train의 타겟 구성: Counter({1.0: 38, 0.0: 37, 2.0: 37})\n",
      "\ty_test의 타겟 구성: Counter({0.0: 13, 2.0: 13, 1.0: 12}) \n",
      "\n",
      "Sample 2 ==> train_index: [0 1 2], test_index: [26 27 28]\n",
      "\tX_train의 비율: 0.75, X_test의 비율: 0.25\n",
      "\ty_train의 타겟 구성: Counter({0.0: 38, 2.0: 38, 1.0: 37})\n",
      "\ty_test의 타겟 구성: Counter({1.0: 13, 0.0: 12, 2.0: 12}) \n",
      "\n",
      "Sample 3 ==> train_index: [0 1 2], test_index: [38 39 40]\n",
      "\tX_train의 비율: 0.75, X_test의 비율: 0.25\n",
      "\ty_train의 타겟 구성: Counter({0.0: 38, 2.0: 38, 1.0: 37})\n",
      "\ty_test의 타겟 구성: Counter({1.0: 13, 0.0: 12, 2.0: 12}) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=4)\n",
    "# 분할 시 y를 고려해야 하기 때문에 split에 y를 입력!\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    print(f\"Sample {i} ==> train_index: {train_index[:3]}, test_index: {test_index[:3]}\")\n",
    "    X_train, X_test, y_train, y_test = X.iloc[train_index, :], X.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n",
    "    print(\"\\tX_train의 비율: %0.2f, X_test의 비율: %0.2f\" %(len(X_train)/len(X), len(X_test)/len(X)))\n",
    "    print(\"\\ty_train의 타겟 구성:\", Counter(y_train['target']))\n",
    "    print(\"\\ty_test의 타겟 구성:\", Counter(y_test['target']), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "still-gardening",
   "metadata": {
    "id": "composed-insured"
   },
   "source": [
    "### -  Group K-fold 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-scenario",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "prospective-steps",
    "outputId": "6e768888-fc26-4ee2-d061-47d29dd0c1c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'g1': 49, 'g2': 39, 'g3': 32, 'g0': 30})\n",
      "   sepal length  sepal width  petal length  petal width  target group\n",
      "0           5.1          3.5           1.4          0.2     0.0    g0\n",
      "1           4.9          3.0           1.4          0.2     0.0    g3\n",
      "2           4.7          3.2           1.3          0.2     0.0    g2\n"
     ]
    }
   ],
   "source": [
    "# group 변수가 있는 데이터를 생성\n",
    "## group의 수준은 g0, g1, g2, g3의 4종류가 있다.\n",
    "iris2 = iris.copy()\n",
    "iris2['group'] = iris2['target'].apply(lambda x: f\"g{int(np.random.randint(0,4,1))}\")\n",
    "print(Counter(iris2['group']))\n",
    "print(iris2.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "original-being",
   "metadata": {
    "id": "horizontal-sharing",
    "outputId": "4f7946d2-e517-4fba-a478-a5699ae86c4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0 ==> train_index: [0 1 2], test_index: [3 4 8]\n",
      "\tX_train의 비율: 0.67, X_test의 비율: 0.33\n",
      "\ttrain의 타겟 구성: Counter({2.0: 36, 0.0: 34, 1.0: 31})\n",
      "\ttest의 타겟 구성: Counter({1.0: 19, 0.0: 16, 2.0: 14})\n",
      "\ttrain의 그룹 구성: Counter({'g2': 39, 'g3': 32, 'g0': 30})\n",
      "\ttest의 그룹 구성: Counter({'g1': 49}) \n",
      "\n",
      "Sample 1 ==> train_index: [0 1 3], test_index: [ 2  7 12]\n",
      "\tX_train의 비율: 0.74, X_test의 비율: 0.26\n",
      "\ttrain의 타겟 구성: Counter({0.0: 40, 1.0: 37, 2.0: 34})\n",
      "\ttest의 타겟 구성: Counter({2.0: 16, 1.0: 13, 0.0: 10})\n",
      "\ttrain의 그룹 구성: Counter({'g1': 49, 'g3': 32, 'g0': 30})\n",
      "\ttest의 그룹 구성: Counter({'g2': 39}) \n",
      "\n",
      "Sample 2 ==> train_index: [0 2 3], test_index: [1 5 6]\n",
      "\tX_train의 비율: 0.79, X_test의 비율: 0.21\n",
      "\ttrain의 타겟 구성: Counter({0.0: 41, 1.0: 40, 2.0: 37})\n",
      "\ttest의 타겟 구성: Counter({2.0: 13, 1.0: 10, 0.0: 9})\n",
      "\ttrain의 그룹 구성: Counter({'g1': 49, 'g2': 39, 'g0': 30})\n",
      "\ttest의 그룹 구성: Counter({'g3': 32}) \n",
      "\n",
      "Sample 3 ==> train_index: [1 2 3], test_index: [ 0 10 16]\n",
      "\tX_train의 비율: 0.80, X_test의 비율: 0.20\n",
      "\ttrain의 타겟 구성: Counter({2.0: 43, 1.0: 42, 0.0: 35})\n",
      "\ttest의 타겟 구성: Counter({0.0: 15, 1.0: 8, 2.0: 7})\n",
      "\ttrain의 그룹 구성: Counter({'g1': 49, 'g2': 39, 'g3': 32})\n",
      "\ttest의 그룹 구성: Counter({'g0': 30}) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "X = iris2.drop(['target', 'group'], axis=1)\n",
    "y = iris2.filter(['target'])\n",
    "group = iris2.filter(['group'])\n",
    "gkf = GroupKFold(n_splits=4)\n",
    "# 분할 시 group을 고려해야 하기 때문에 split에 group를 입력!\n",
    "for i, (train_index, test_index) in enumerate(gkf.split(X, y, group)):\n",
    "    print(f\"Sample {i} ==> train_index: {train_index[:3]}, test_index: {test_index[:3]}\")\n",
    "    X_train, X_test, y_train, y_test = X.iloc[train_index, :], X.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n",
    "    print(\"\\tX_train의 비율: %0.2f, X_test의 비율: %0.2f\" %(len(X_train)/len(X), len(X_test)/len(X)))\n",
    "    print(\"\\ttrain의 타겟 구성:\", Counter(y_train['target']))\n",
    "    print(\"\\ttest의 타겟 구성:\", Counter(y_test['target']))\n",
    "    print(\"\\ttrain의 그룹 구성:\", Counter(group.iloc[train_index]['group']))\n",
    "    print(\"\\ttest의 그룹 구성:\", Counter(group.iloc[test_index]['group']), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accredited-monroe",
   "metadata": {
    "id": "contrary-uncle"
   },
   "source": [
    "## 3-3. 교차 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "insured-laser",
   "metadata": {
    "id": "headed-strap"
   },
   "source": [
    "### - 분할 샘플들로 교차 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stock-transcription",
   "metadata": {
    "id": "given-absence",
    "outputId": "f34dd2a2-d23b-45cd-99b0-ffb05fede8ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fit_time  score_time  test_score  train_score\n",
      "0  0.024765    0.002182    0.894737     0.955357\n",
      "1  0.017696    0.001794    0.947368     0.964286\n",
      "2  0.018460    0.001895    0.945946     0.955752\n",
      "3  0.020559    0.001763    1.000000     0.938053\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "X = iris.drop('target', axis=1)\n",
    "y = iris['target']\n",
    "LOGREG = LogisticRegression(max_iter = 300, C = 0.1) # 학습 모델 정의\n",
    "SKF = StratifiedKFold(n_splits=4) # 데이터 분할 방법 정의\n",
    "result = cross_validate(LOGREG, X, y, cv = SKF, return_train_score=True) #교차 검증\n",
    "print(DataFrame(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flying-aberdeen",
   "metadata": {
    "id": "south-reach"
   },
   "source": [
    "### - 파라미터 후보들로 교차 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forty-apollo",
   "metadata": {
    "id": "judicial-inspiration",
    "outputId": "e2dcd999-bb6f-48f0-b732-8dece37144dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최상의 교차 검증 점수: 0.97\n",
      "최적의 매개변수: {'C': 1, 'solver': 'lbfgs'}\n",
      "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
      "0       0.012633      0.001947         0.001974        0.000203    0.01   \n",
      "1       0.002517      0.000178         0.001723        0.000059    0.01   \n",
      "2       0.018816      0.001285         0.001765        0.000030     0.1   \n",
      "3       0.002247      0.000101         0.001536        0.000013     0.1   \n",
      "4       0.027849      0.003706         0.002001        0.000142       1   \n",
      "5       0.004570      0.002461         0.002332        0.000648       1   \n",
      "\n",
      "  param_solver                              params  split0_test_score  \\\n",
      "0        lbfgs      {'C': 0.01, 'solver': 'lbfgs'}           0.815789   \n",
      "1    liblinear  {'C': 0.01, 'solver': 'liblinear'}           0.684211   \n",
      "2        lbfgs       {'C': 0.1, 'solver': 'lbfgs'}           0.894737   \n",
      "3    liblinear   {'C': 0.1, 'solver': 'liblinear'}           0.815789   \n",
      "4        lbfgs         {'C': 1, 'solver': 'lbfgs'}           0.973684   \n",
      "5    liblinear     {'C': 1, 'solver': 'liblinear'}           1.000000   \n",
      "\n",
      "   split1_test_score  split2_test_score  split3_test_score  mean_test_score  \\\n",
      "0           0.894737           0.783784           0.945946         0.860064   \n",
      "1           0.684211           0.648649           0.648649         0.666430   \n",
      "2           0.947368           0.945946           1.000000         0.947013   \n",
      "3           0.842105           0.837838           0.783784         0.819879   \n",
      "4           0.973684           0.945946           1.000000         0.973329   \n",
      "5           0.947368           0.864865           1.000000         0.953058   \n",
      "\n",
      "   std_test_score  rank_test_score  \n",
      "0        0.063947                4  \n",
      "1        0.017781                6  \n",
      "2        0.037221                3  \n",
      "3        0.023109                5  \n",
      "4        0.019114                1  \n",
      "5        0.055266                2  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "LOGREG = LogisticRegression(max_iter = 300) # 학습 모델 정의\n",
    "param_grid={'C':[0.01, 0.1, 1], 'solver':['lbfgs', 'liblinear']} #파라미터 후보 정의\n",
    "SKF = StratifiedKFold(n_splits=4) # 데이터 분할 방법 정의\n",
    "grid = GridSearchCV(LOGREG, param_grid, cv = SKF) #교차 검증\n",
    "grid.fit(X, y)\n",
    "print(\"최상의 교차 검증 점수: {:.2f}\".format(grid.best_score_))\n",
    "print(\"최적의 매개변수: {}\".format(grid.best_params_))\n",
    "print(DataFrame(grid.cv_results_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minor-movement",
   "metadata": {},
   "source": [
    "# 연습문제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-shirt",
   "metadata": {},
   "source": [
    "### - 1번 문제 풀이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "informed-finish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age         job  marital  education default  balance housing loan  \\\n",
      "0   30  unemployed  married    primary      no     1787      no   no   \n",
      "1   33    services  married  secondary      no     4789     yes  yes   \n",
      "2   35  management   single   tertiary      no     1350     yes   no   \n",
      "\n",
      "    contact month   y  \n",
      "0  cellular   oct  no  \n",
      "1  cellular   may  no  \n",
      "2  cellular   apr  no  \n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "df = read_csv('https://raw.githubusercontent.com/algoboni/pythoncodebook1-1/main/practice1_bank.csv')\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "colonial-quebec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age         job  marital  education default  balance housing loan  \\\n",
      "0   30  unemployed  married    primary      no     1787      no   no   \n",
      "1   33    services  married  secondary      no     4789     yes  yes   \n",
      "2   35  management   single   tertiary      no     1350     yes   no   \n",
      "\n",
      "    contact month   y  \n",
      "0  cellular   oct  no  \n",
      "1  cellular   may  no  \n",
      "2  cellular   apr  no  \n",
      "\n",
      "DICT 생성 확인\n",
      "['no' 'yes']\n",
      "[0, 1]\n",
      "{'no': 0, 'yes': 1}\n"
     ]
    }
   ],
   "source": [
    "# 범주형 변수들을 레이블 인코딩을 통해 전처리 한다.\n",
    "df2 = df.copy()\n",
    "for col in [i for i in df.columns if df[i].dtypes==object]:\n",
    "    DICT = dict(zip(df[col].unique(), [i for i in range(df[col].nunique())]))\n",
    "    df2[col] = df2[col].map(DICT)\n",
    "print(df.head(3))\n",
    "\n",
    "# 마지막 변수의 DICT 확인\n",
    "print(\"\\nDICT 생성 확인\")\n",
    "print(df[col].unique())\n",
    "print([i for i in range(df[col].nunique())])\n",
    "print(DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "victorian-canberra",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최상의 교차 검증 점수: 0.88\n",
      "최적의 매개변수: {'max_depth': 7}\n",
      "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0       0.220673      0.022650         0.015120        0.001630   \n",
      "1       0.224396      0.006214         0.014856        0.000865   \n",
      "2       0.241268      0.008658         0.015578        0.000848   \n",
      "3       0.251823      0.004222         0.016674        0.000590   \n",
      "\n",
      "  param_max_depth            params  split0_test_score  split1_test_score  \\\n",
      "0               5  {'max_depth': 5}           0.885942           0.884615   \n",
      "1               6  {'max_depth': 6}           0.887268           0.883289   \n",
      "2               7  {'max_depth': 7}           0.887268           0.883289   \n",
      "3               8  {'max_depth': 8}           0.885942           0.884615   \n",
      "\n",
      "   split2_test_score  split3_test_score  split4_test_score  split5_test_score  \\\n",
      "0           0.883289           0.885790           0.884462           0.884462   \n",
      "1           0.880637           0.887118           0.885790           0.883134   \n",
      "2           0.884615           0.887118           0.884462           0.883134   \n",
      "3           0.884615           0.885790           0.885790           0.883134   \n",
      "\n",
      "   mean_test_score  std_test_score  rank_test_score  \n",
      "0         0.884760        0.000896                3  \n",
      "1         0.884539        0.002395                4  \n",
      "2         0.884981        0.001657                1  \n",
      "3         0.884981        0.000993                1  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier() # 학습 모델 정의\n",
    "param_grid={'max_depth':[5, 6, 7, 8]} #파라미터 후보 정의\n",
    "SKF = StratifiedKFold(n_splits=6) # 데이터 분할 방법 정의\n",
    "grid = GridSearchCV(rf, param_grid, cv = SKF) #교차 검증\n",
    "\n",
    "X = df2.drop('y', axis=1)\n",
    "y = df2['y']\n",
    "grid.fit(X, y)\n",
    "\n",
    "print(\"최상의 교차 검증 점수: {:.2f}\".format(grid.best_score_))\n",
    "print(\"최적의 매개변수: {}\".format(grid.best_params_))\n",
    "print(DataFrame(grid.cv_results_))\n",
    "# 매개변수들을 활용한 교차분석 결과, max_depth가 7일 때 가장 높은 성능을 보이는 것으로 확인하였다."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
